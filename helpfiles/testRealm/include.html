<head><title>include</title><link type="text/css" href="../_static/default.css" rel="stylesheet"/></head><body><div class="Section"><h1>include</h1></div><div class="Section"><p><strong>include</strong>(&lt;string,list&gt;  libraries)</p></div><div class="Section"><h2>Description</h2><p>Includes the listed library or libraries without executing any code. libraries is a string containing one file uri or a list containing several strings with file uri&rsquo;s. After including a library the routines inside that library become part of the current robot.</p></div><div class="Examples"><h2>Examples</h2><ul><li><p class="First">Executing the following code:</p><div class="highlight"><pre>include (&quot;testbots/routines.sbot&quot;);
</pre></div></li><li><p class="First">log (cleanurlsimple(&quot;www.xillio.com/#main?parameter=test&quot;, true, true));</p><div class="highlight"><pre></pre></div></li><li><p class="First">will print:</p><div class="highlight"><pre>www.xillio.com
</pre></div></li><li><p class="First">Assuming we have a text file routines.sbot, which contains the following:</p><div class="highlight"><pre>cleanurlsimple = routine(url, stripanchors, stripvars) {
    if (stripanchors == true) {
        url = replace(url, &quot;#.*&quot;, &quot;&quot;); // strip anchors
    }
    if (stripvars == true) {
        url = replace(url, &quot;\?.*|\&amp;.*|target=.*&quot;, &quot;&quot;); // strip appended variables
    }
    url = replace(url, &quot;/$&quot;, &quot;&quot;); // strip trailing slash
    url = urldecode(url);
</pre></div></li><li><p class="First">    return(url);</p><div class="highlight"><pre>}
</pre></div></li><li><p class="First">geturl = routine (url) {</p><div class="highlight"><pre>    // gets the url from a loadpage errormessage (assumes it is at the end of the message)
    result = regex (url, &quot;.*(https?://.*$)|.*(www\\..*$)&quot;);
    if (variabletype (result) == &quot;list&quot;) {
        return (result [1]);
    }
    return (null);
}
</pre></div></li><li><p class="First">We could also include the above code as two separate libraries, by splitting them into two separate files cleanurl.sbot and geturl.sbot:</p><div class="highlight"><pre>include ({&quot;testbots/cleanurl.sbot&quot;, &quot;testbots/geturl.sbot&quot;});
</pre></div></li><li><p class="First">Note that the latter is probably the most modular and maintainable way of including routines, while the former seems more convenient.</p><div class="highlight"><pre></pre></div></li></ul></div><div class="Tags"><h2>Tags</h2><ul><li><p><a href="../testRealm/ callbot.html"> callbot</a></p></li><li><p><a href="../testRealm/Language.html">Language</a></p></li></ul></div></body>